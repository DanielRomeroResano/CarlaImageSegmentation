{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4894e1-95b1-4b9e-b6e4-95c8cb23e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7dc9f9-d25c-4b7c-8d3a-aad263e39ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtPath = \"_conv3/\"\n",
    "rgbPath = \"_out/\"\n",
    "\n",
    "gtFileNames = os.listdir(gtPath)\n",
    "outFileNames = os.listdir(rgbPath)\n",
    "\n",
    "matchingFiles = set(outFileNames) & set(gtFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91426ce9-aee0-42d0-bec3-435726e9ab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_11404\\233777074.py:6: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  FileNames = random.sample(matchingFiles, NumTrainingImages)\n"
     ]
    }
   ],
   "source": [
    "NumTrainingImages = 10000\n",
    "StartingIndex = 0\n",
    "\n",
    "import random\n",
    "\n",
    "FileNames = random.sample(matchingFiles, NumTrainingImages)\n",
    "\n",
    "                            \n",
    "gtFileNames = gtFileNames[StartingIndex:StartingIndex+NumTrainingImages]\n",
    "outFileNames = outFileNames [StartingIndex:StartingIndex+NumTrainingImages]\n",
    "\n",
    "for i in range(0,NumTrainingImages):\n",
    "    gtFileNames[i] = gtPath + FileNames[i]\n",
    "    outFileNames[i] = rgbPath + FileNames[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3352f1d3-8e30-4b26-a147-ab8474b2fe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gtFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceea0b4b-c844-4e47-8317-8cc8f7d2dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(outFileNames, gtFileNames, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83a41c5-f325-4b08-9cc1-d7813c3550b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(outPath, gtPath):\n",
    "    \n",
    "    img = tf.io.read_file(outPath)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = img[:1000, 460:1460, :] # Crop the photo (bonnet & make it square)\n",
    "    img = tf.image.resize(img, (256, 256), method='nearest')\n",
    "\n",
    "    mask = tf.io.read_file(gtPath)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.cast(mask, tf.float32) / 255.0\n",
    "    mask = mask[:1000, 460:1460, :] # Crop the bonnet\n",
    "    mask = tf.image.resize(mask, (256, 256), method='nearest')\n",
    "    \n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b63310f-f7af-4495-8301-eddfbf21aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "bufferSize = 500\n",
    "\n",
    "def genDataset(outPath, gtPath, bufferSize, batchSize):\n",
    "    \n",
    "    imageList = tf.constant(outPath) \n",
    "    maskList = tf.constant(gtPath)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((imageList, maskList))\n",
    "    dataset = dataset.map(loadImage, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.cache().shuffle(bufferSize).batch(batchSize)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bb06984-de8d-4eb3-924b-c4a70c98e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = genDataset(X_train, y_train, bufferSize, batchSize)\n",
    "valDataset = genDataset(X_val, y_val, bufferSize, batchSize)\n",
    "testDataset = genDataset(X_test, y_test, bufferSize, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9519a9ae-5345-4b52-a76b-a75aa750037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_11404\\2492856641.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel, Hyperband\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from kerastuner import HyperModel, Hyperband\n",
    "\n",
    "\n",
    "def encoderBlock(inputs, filters, maxPool=True):\n",
    "    \n",
    "    X = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    X = Conv2D(filters, 3, padding=\"same\")(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    skip = X\n",
    "    \n",
    "    if maxPool:\n",
    "        X = MaxPooling2D(pool_size=(2, 2))(X)        \n",
    "\n",
    "    return X, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7aabc41-0f11-4235-8803-58f5f58fce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoderBlock(inputs, skip, filters):\n",
    "    \n",
    "    X = Conv2DTranspose(filters, 3, strides=(2,2), padding=\"same\")(inputs) \n",
    "    \n",
    "    X = concatenate([X, skip], axis=3) #concat prev skip connection\n",
    "\n",
    "    X = Conv2D(filters, 3, padding=\"same\")(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Conv2D(filters, 3, padding=\"same\")(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6021a04d-3f46-44ce-8373-9ec9a6844ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "\n",
    "class UNetHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        inputs = Input(self.input_shape)\n",
    "        \n",
    "        # Define hyperparameters to tune\n",
    "        filters = hp.Choice('filters', [32, 64, 128])\n",
    "        \n",
    "        # Encoder\n",
    "        X1, S1 = encoderBlock(inputs, filters, maxPool=True)\n",
    "        X2, S2 = encoderBlock(X1, filters * 2, maxPool=True)\n",
    "        X3, S3 = encoderBlock(X2, filters * 4, maxPool=True)\n",
    "        X4, S4 = encoderBlock(X3, filters * 8, maxPool=True)\n",
    "        X5, S5 = encoderBlock(X4, filters * 16, maxPool=False)\n",
    "        \n",
    "        # Decoder\n",
    "        X6 = decoderBlock(X5, S4, filters * 8)\n",
    "        X7 = decoderBlock(X6, S3,  filters * 4)\n",
    "        X8 = decoderBlock(X7, S2,  filters = filters * 2)\n",
    "        X9 = decoderBlock(X8, S1,  filters = filters)\n",
    "        \n",
    "        X10 = Conv2D(filters, 3,activation='relu', padding='same')(X9)\n",
    "        X11 = Conv2D(filters=self.num_classes, kernel_size=(1, 1), activation='sigmoid', padding='same')(X10)\n",
    "        \n",
    "        modelUnet = Model(inputs=inputs, outputs=X11)\n",
    "        modelUnet.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "        modelUnet.summary()\n",
    "        return modelUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147247ef-51ab-4d36-913f-37f3f031c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_dir\\unet_hyperband\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "imgShape = (256,256,3)\n",
    "labels = 2 # True/False\n",
    "\n",
    "hypermodel = UNetHyperModel(input_shape=imgShape, num_classes=labels)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='unet_hyperband'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b2bdb2f-942a-4017-aa64-d53ff08b8edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 16m 50s]\n",
      "val_accuracy: 0.9869365692138672\n",
      "\n",
      "Best val_accuracy So Far: 0.9869365692138672\n",
      "Total elapsed time: 02h 03m 45s\n",
      "Best hyperparameters: <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x000001B619842790>\n"
     ]
    }
   ],
   "source": [
    "# Run the hyperparameter search\n",
    "tuner.search(trainDataset, validation_data=valDataset)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best hyperparameters: {best_hps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73655181-878b-456f-9600-691772992eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps.get('filters')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
